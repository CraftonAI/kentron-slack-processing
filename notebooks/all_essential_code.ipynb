{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory path\n",
    "directory_path = \"../csv2/\"\n",
    "\n",
    "# Define the column names\n",
    "column_names = [\"user\", \"text\", \"type\", \"ts\"]\n",
    "\n",
    "# Create an empty dataframe\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "# Loop through all subdirectories starting with \"D05\"\n",
    "for subdir, dirs, files in os.walk(directory_path):\n",
    "    if subdir.startswith(directory_path + \"D05\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                # Read the csv file\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                temp_df = pd.read_csv(file_path)\n",
    "                \n",
    "                # Check if all required columns are present\n",
    "                if all(col in temp_df.columns for col in column_names):\n",
    "                    # Append the dataframe to the main dataframe\n",
    "                    df = df.append(temp_df[column_names], ignore_index=True)\n",
    "\n",
    "df['ts'] = pd.to_datetime(df['ts'], unit='s')\n",
    "\n",
    "# Save the dataframe to a csv file\n",
    "df.to_csv(\"merged_msg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def merge_csv_files():\n",
    "    # Take user input for usernames\n",
    "    username1 = input(\"Enter username 1: \")\n",
    "    username2 = input(\"Enter username 2: \")\n",
    "\n",
    "    # Read the dms_output.csv file\n",
    "    dms_data = pd.read_csv('../processed_data/dms_output.csv')\n",
    "\n",
    "    # Filter the data based on the usernames\n",
    "    filtered_data = dms_data[(dms_data['member_1'] == username1) & (dms_data['member_2'] == username2)]\n",
    "\n",
    "    if filtered_data.empty:\n",
    "        print(\"No matching records found\")\n",
    "        return\n",
    "\n",
    "    # Get the folder name from the id column of the matched record\n",
    "    folder_name = filtered_data.iloc[0]['id']\n",
    "\n",
    "    # Search for the folder with the same name\n",
    "    folder_path = None\n",
    "    for root, dirs, files in os.walk('../csv2/'):\n",
    "        if folder_name in dirs:\n",
    "            folder_path = os.path.join(root, folder_name)\n",
    "            break\n",
    "\n",
    "    if folder_path is None:\n",
    "        print(\"Folder not found\")\n",
    "        return\n",
    "    # Merge all the CSV files in the folder\n",
    "    merged_data = pd.DataFrame()\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            df = pd.read_csv(file_path, usecols=[\"user\", \"text\", \"type\", \"ts\"])\n",
    "            df['ts'] = pd.to_datetime(df['ts'], unit='s')  # Convert ts column to human-readable timestamp\n",
    "            merged_data = pd.concat([merged_data, df])\n",
    "\n",
    "    # Save the merged data to a new CSV file\n",
    "    merged_data.to_csv('merged_conversations.csv', index=False)\n",
    "    print(\"CSV files merged successfully!\")\n",
    "\n",
    "# Usage example\n",
    "merge_csv_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide each user in the 'members' column into different columns\n",
    "members_df = channels_df['members'].str.split(',', expand=True)\n",
    "members_df = members_df.replace({',':'', '\\[':'', '\\]':'', '\\'':''}, regex=True)\n",
    "\n",
    "# Rename the columns\n",
    "members_df.columns = [f\"member_{i+1}\" for i in range(members_df.shape[1])]\n",
    "\n",
    "# Concatenate the original DataFrame with the new columns\n",
    "channels_df = pd.concat([channels_df, members_df], axis=1)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "channels_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dms_df = pd.read_csv('../csv2/dms.csv')\n",
    "\n",
    "# Divide each user in the 'members' column into different columns\n",
    "members_df = dms_df['members'].str.split(',', expand=True)\n",
    "members_df = members_df.replace({',':'', '\\[':'', '\\]':'', '\\'':''}, regex=True)\n",
    "\n",
    "# Rename the columns\n",
    "members_df.columns = [f\"member_{i+1}\" for i in range(members_df.shape[1])]\n",
    "members_df['member_2'] = members_df['member_2'].str.replace(' ', '')\n",
    "members_df = members_df.replace(user_id_to_username)\n",
    "\n",
    "# Concatenate the original DataFrame with the new columns\n",
    "dms_df = pd.concat([dms_df, members_df], axis=1)\n",
    "\n",
    "# # rename user id with username\n",
    "# for column in dms_df.columns:\n",
    "#     if column.startswith('member_'):\n",
    "#         dms_df[column] = dms_df[column].replace(user_id_to_username)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "dms_df.to_csv('../processed_data/dms_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from fastapi import FastAPI, UploadFile\n",
    "\n",
    "# Establish a connection to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"your_database_name\",\n",
    "    user=\"your_username\",\n",
    "    password=\"your_password\"\n",
    ")\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/process_zip\")\n",
    "async def process_zip(file: UploadFile):\n",
    "    # Specify the directory to extract the zip file to\n",
    "    extract_directory = '../data4/raw/'\n",
    "\n",
    "    # Save the zip file\n",
    "    zip_file_path = os.path.join(extract_directory, file.filename)\n",
    "    with open(zip_file_path, 'wb') as f:\n",
    "        f.write(await file.read())\n",
    "\n",
    "    # Extract the zip file\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_directory)\n",
    "\n",
    "    # Get a list of JSON files in the directory\n",
    "    json_files = [os.path.join(root, f) for root, _, files in os.walk(extract_directory) for f in files if f.endswith('.json')]\n",
    "\n",
    "    # Process each JSON file and convert it to a Pandas DataFrame\n",
    "    df_list = []\n",
    "    for json_file in json_files:\n",
    "        with open(json_file, encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        df = pd.json_normalize(data)\n",
    "        df_list.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Save the DataFrame to the PostgreSQL database\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"CREATE TABLE IF NOT EXISTS processed_files (id SERIAL PRIMARY KEY, file_name VARCHAR, file_data JSONB)\")\n",
    "    for index, row in df.iterrows():\n",
    "        file_name = row['file_name']\n",
    "        file_data = row.to_json()\n",
    "        cursor.execute(\"INSERT INTO processed_files (file_name, file_data) VALUES (%s, %s)\", (file_name, file_data))\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "\n",
    "    return {\"message\": \"Zip file processed successfully\"}\n",
    "\n",
    "@app.get(\"/create_user_mapping\")\n",
    "async def create_user_mapping():\n",
    "    # Read the users.csv file\n",
    "    csv_file_path = '../csv/users.csv'\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Create a dictionary for mapping user_id with username\n",
    "    user_mapping = df.set_index('user_id')['username'].to_dict()\n",
    "\n",
    "    # Save the user_mapping to the PostgreSQL database\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"CREATE TABLE IF NOT EXISTS user_mapping (user_id VARCHAR PRIMARY KEY, username VARCHAR)\")\n",
    "    for user_id, username in user_mapping.items():\n",
    "        cursor.execute(\"INSERT INTO user_mapping (user_id, username) VALUES (%s, %s)\", (user_id, username))\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "\n",
    "    return {\"message\": \"User mapping created successfully\"}\n",
    "\n",
    "@app.get(\"/create_channel_info\")\n",
    "async def create_channel_info():\n",
    "    # Read the channels.csv file\n",
    "    csv_file_path = '../csv/channels.csv'\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Create a new DataFrame with channel information\n",
    "    channel_info_df = pd.DataFrame(columns=['channel_name', 'members', 'type'])\n",
    "\n",
    "    # Iterate through each channel\n",
    "    for index, row in df.iterrows():\n",
    "        channel_name = row['channel_name']\n",
    "        members = row['members']\n",
    "        channel_type = row['type']\n",
    "\n",
    "        # Split the members string into a list\n",
    "        members_list = members.split(',')\n",
    "\n",
    "        # Create a new row for each member in the channel\n",
    "        for member in members_list:\n",
    "            channel_info_df = channel_info_df.append({'channel_name': channel_name, 'members': member, 'type': channel_type}, ignore_index=True)\n",
    "\n",
    "    # Save the channel information to the PostgreSQL database\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"CREATE TABLE IF NOT EXISTS channel_info (channel_name VARCHAR, members VARCHAR, type VARCHAR)\")\n",
    "    for index, row in channel_info_df.iterrows():\n",
    "        channel_name = row['channel_name']\n",
    "        members = row['members']\n",
    "        channel_type = row['type']\n",
    "        cursor.execute(\"INSERT INTO channel_info (channel_name, members, type) VALUES (%s, %s, %s)\", (channel_name, members, channel_type))\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "\n",
    "    return {\"message\": \"Channel information created successfully\"}\n",
    "\n",
    "@app.get(\"/get_single_user_messages\")\n",
    "async def get_single_user_messages(user_id: str):\n",
    "    # Read the messages.csv file\n",
    "    csv_file_path = '../csv/messages.csv'\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Filter the messages for the specified user_id\n",
    "    filtered_df = df[df['user_id'] == user_id]\n",
    "\n",
    "    # Save the filtered messages to the PostgreSQL database\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"CREATE TABLE IF NOT EXISTS single_user_messages (user_id VARCHAR, message VARCHAR)\")\n",
    "    for index, row in filtered_df.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        message = row['message']\n",
    "        cursor.execute(\"INSERT INTO single_user_messages (user_id, message) VALUES (%s, %s)\", (user_id, message))\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "\n",
    "    return {\"message\": \"Single user messages created successfully\"}\n",
    "\n",
    "@app.get(\"/get_two_user_messages\")\n",
    "async def get_two_user_messages(user_id1: str, user_id2: str):\n",
    "    # Read the messages.csv file\n",
    "    csv_file_path = '../csv/messages.csv'\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Filter the messages for the specified user_id1 and user_id2\n",
    "    filtered_df = df[(df['user_id'] == user_id1) | (df['user_id'] == user_id2)]\n",
    "\n",
    "    # Save the filtered messages to the PostgreSQL database\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"CREATE TABLE IF NOT EXISTS two_user_messages (user_id VARCHAR, message VARCHAR)\")\n",
    "    for index, row in filtered_df.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        message = row['message']\n",
    "        cursor.execute(\"INSERT INTO two_user_messages (user_id, message) VALUES (%s, %s)\", (user_id, message))\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "\n",
    "    return {\"message\": \"Two user messages created successfully\"}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
